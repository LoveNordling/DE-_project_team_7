{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Session\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import timeit \n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.131:7077\") \\\n",
    "        .appName(\"Team7_code.ipynb\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.cores.max\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")\n",
    "print(\"Started Session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add(a, b):\n",
    "    # commutative and associative!\n",
    "    return a + b\n",
    "\n",
    "rdd = spark_context.parallelize([1, 2, 3, 4, 5, 6], 3)\n",
    "\n",
    "result = rdd\\\n",
    "            .filter(lambda x: x % 2 == 0)\\\n",
    "            .map(lambda x: x ** 2)\\\n",
    "            .reduce(add)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: long (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: boolean (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- ups: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_spark_dataframe(filename):\n",
    "    df = spark_session.read.json('hdfs://192.168.2.131:9000/user/ubuntu/{}'.format(filename))\n",
    "    return df\n",
    "\n",
    "def create_joint_spark_dataframe(regex):\n",
    "    \n",
    "\n",
    "\n",
    "df = create_spark_dataframe('RC_2005-12.json')\n",
    "\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of comments: 1075\n",
      "+---------------+-----+\n",
      "|         author|count|\n",
      "+---------------+-----+\n",
      "|      [deleted]|  185|\n",
      "|   michaelneale|   21|\n",
      "|       symbiont|   21|\n",
      "|       mattknox|   19|\n",
      "|            chu|   16|\n",
      "|     paulgraham|   15|\n",
      "|            e40|   13|\n",
      "|       fnord123|   12|\n",
      "|          jcage|   10|\n",
      "|         stesch|    9|\n",
      "|        beza1e1|    9|\n",
      "|        bugbear|    9|\n",
      "|         TronXD|    9|\n",
      "|         rdtiii|    9|\n",
      "|       enjahova|    9|\n",
      "|       JimThome|    8|\n",
      "| JonathanGCohen|    8|\n",
      "|      lynxcat73|    8|\n",
      "|      drewyates|    7|\n",
      "|theycallmemorty|    7|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "execution time 4.649566684005549s\n",
      "+-------------+----------+\n",
      "|       author|sum(score)|\n",
      "+-------------+----------+\n",
      "|   paulgraham|        98|\n",
      "|     mattknox|        77|\n",
      "|    [deleted]|        58|\n",
      "|      bugbear|        43|\n",
      "| michaelneale|        39|\n",
      "|     dstowell|        38|\n",
      "|         spez|        36|\n",
      "|      AaronSw|        30|\n",
      "|        sempf|        29|\n",
      "|     JimThome|        29|\n",
      "|    bolinfest|        28|\n",
      "|       davidw|        27|\n",
      "|          Zak|        26|\n",
      "|     symbiont|        25|\n",
      "|     binladen|        24|\n",
      "|     enjahova|        23|\n",
      "|         cg84|        23|\n",
      "|brendankohler|        21|\n",
      "|       dylanm|        20|\n",
      "|     beastboy|        19|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc, col\n",
    "\n",
    "num_comments = df.count()\n",
    "print('number of comments: {}'.format(num_comments))\n",
    "\n",
    "start_time_0 = timeit.default_timer() \n",
    "\n",
    "author_comment_counts = df.groupBy('author').count().sort(desc(\"count\"))\n",
    "author_comment_counts.show()\n",
    "\n",
    "print(\"execution time {}s\".format(timeit.default_timer()-start_time_0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|       author|sum(score)|\n",
      "+-------------+----------+\n",
      "|   paulgraham|        98|\n",
      "|     mattknox|        77|\n",
      "|    [deleted]|        58|\n",
      "|      bugbear|        43|\n",
      "| michaelneale|        39|\n",
      "|     dstowell|        38|\n",
      "|         spez|        36|\n",
      "|      AaronSw|        30|\n",
      "|     JimThome|        29|\n",
      "|        sempf|        29|\n",
      "|    bolinfest|        28|\n",
      "|       davidw|        27|\n",
      "|          Zak|        26|\n",
      "|     symbiont|        25|\n",
      "|     binladen|        24|\n",
      "|     enjahova|        23|\n",
      "|         cg84|        23|\n",
      "|brendankohler|        21|\n",
      "|       dylanm|        20|\n",
      "|     beastboy|        19|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "execution time 11.968498889997136s\n"
     ]
    }
   ],
   "source": [
    "start_time_0 = timeit.default_timer() \n",
    "df.groupBy('author').sum('score').sort(desc(\"sum(score)\")).show()\n",
    "print(\"execution time {}s\".format(timeit.default_timer()-start_time_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended Session\n"
     ]
    }
   ],
   "source": [
    "# release the cores for another application!\n",
    "spark_context.stop()\n",
    "print(\"Ended Session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
